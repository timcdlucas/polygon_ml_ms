\documentclass[review]{elsarticle}


\usepackage{graphicx}
\usepackage{amsmath}

\usepackage{subcaption}

\usepackage{amssymb}
\usepackage{array}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]

%\usepackage{numcompress}\bibliographystyle{model3-num-names}

\usepackage{natbib}
%\usepackage[numbers, sort&compress]{natbib}
%\setcitestyle{author[oxford]year}
\bibliographystyle{elsarticle-num}

%\geometry{verbose,tmargin=30mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}
%\input{figures.tex}
%\pagestyle{empty}
\begin{document}
%\templatefigures{}




% Model ensembles with different response variables for base and meta models:



% Spatial and Spatio-temporal Epidemiology
% Special issue: Disease Surveillance and Infectious disease Modeling


\begin{frontmatter}

\title{Improving disaggregation models of malaria incidence by ensembling non-linear models of prevalence}

\author[oxford]{Tim C. D. Lucas\corref{mycorrespondingauthor}}
\cortext[mycorrespondingauthor]{Corresponding author}
\ead{timcdlucas@gmail.com}
\author[oxford]{Anita K. Nandi}
\author[oxford]{Suzanne H. Keddie}
%\author[oxford]{Katherine A. Twohig}
\author[oxford]{Elisabeth G. Chestnutt}
\author[oxford]{Rosalind E. Howes}
%\author[oxford]{Michele Nguyen}
\author[oxford]{Susan F. Rumisha}
\author[oxford]{Rohan Arambepola}
\author[oxford,idm]{Amelia Bertozzi-Villa}
\author[oxford]{Andre Python}
\author[oxford]{Tasmin L. Symons}
\author[oxford]{Justin J. Millar}
\author[oxford]{Punam Amratia}
\author[oxford]{Penelope Hancock}
\author[oxford]{Katherine E. Battle}
\author[oxford]{Ewan Cameron}
\author[oxford,telethon,curtin]{Peter W. Gething}
\author[oxford]{Daniel J. Weiss}



\address[oxford]{Malaria Atlas Project, Big Data Institute, University of Oxford, Oxford, UK}
\address[idm]{Institute for Disease Modeling, Bellevue, WA, USA}
\address[telethon]{Telethon Kids Institute, Perth Childrenâ€™s Hospital, Perth, Australia}
\address[curtin]{Curtin University, Perth, Australia}



\begin{abstract}

Maps of infection rate are one of the core tools needed for the control and elimination of malaria.
Reliable routine surveillance data of malaria incidence is becoming more widely available.
Disaggregation regression is becoming an important model framework for estimating high resolution risk maps from these aggregated data.
However, the aggregation of incidence over large, heterogeneous areas means that these data are underpowered for learning complex, non-linear relationships between the environment and malaria risk.
In contrast, prevalence point-surveys are directly linked to local environmental conditions but are not common in many areas of the world.
A model that combines point surveys and aggregated surveillance data could have the benefits of both but must be able to account for the fact that these two data types measure different malariometric units.
Here, we train multiple non-linear, machine learning models on \emph{Plasmodium falciparum} prevalence point-surveys.
We then ensemble the predictions from these machine learning models with a geostatistical disaggregation regression model that uses malaria incidence, aggregated to administrative units, as response data.
We find that, in four national case studies, using a disaggregation regression model to combine predictions from machine learning models trained on prevalence point-surveys improves model accuracy relative to a baseline disaggregation regression model that only uses linear effects of the raw environmental covariates.

\end{abstract}

\begin{keyword}
Spatial statistics; Disaggregation regression; Stacking; Surveillance data
\end{keyword}

\end{frontmatter}

\linenumbers



\section{Introduction}


% New plan

% We need to do disaggregation but how do we do nonlinear

% We can do machine learning on prevalence and then combine...

% Stacking is a thing and has some nice theory.

% We found that it worked ok.


High-resolution maps of malaria risk are vital for control and elimination \citep{weiss2019mapping, battle2019mapping}.
However, mapping malaria in lower burden countries presents new challenges as traditional mapping of prevalence from cluster-level surveys \cite{weiss2019mapping,battle2019mapping, bhatt2017improved, bhatt2015effect} is often not effective for two reasons.
Firstly, so few individuals are infected that most surveys will detect zero cases \citep{sturrock2016mapping}.
Secondly, there is a lack of nationally representative prevalence surveys in low burden countries \citep{sturrock2016mapping, sturrock2014fine}. 
Routine surveillance data of malaria case counts, often aggregated over administrative regions defined by geographic polygons, is becoming more reliable and more widely available \citep{sturrock2016mapping} and recent work has focussed on methods for estimating high-resolution malaria risk from these data \citep{sturrock2014fine, wilson2017pointless, law2018variational, taylor2017continuous, li2012log, johnson2019spatially}. 
However, the aggregation of cases over space means that the data may be spatially uninformative, especially if the case counts are aggregated over large or heterogeneous areas, because it is unclear where within the polygon, and in which environments, the cases occurred. 
This data is therefore often under-powered for fitting flexible, non-linear models as is required for accurate malaria maps \citep{bhatt2017improved, bhatt2015effect}. 
A method that combines prevalence point-surveys and aggregated surveillance data, and therefore leverages the strength of both, has great potential.

Here we propose a two-stage method.
In the first stage we train a suite of machine learning models, using point-level, binomial prevalence data and environmental covariates.
In the second stage we combine predictions from these models by using them as covariates in a polygon-level, disaggregation regression model that uses  malaria incidence (aggregated to administrative units) as the response.
Unlike joint likelihood models \citep{wang2018generalized}, this method does not combine both prevalence and incidence data within one model.
Instead the aim is to use the prevalence data to find useful non-linear transformations of the environmental covariates which are then subsequently used in the disaggregation regression models.

This modelling scheme has similarities to previous stacking methods used for malaria mapping \citep{bhatt2017improved} and elsewhere \citep{wolpert1992stacked, sill2009feature, hao2019review, breiman1996stacked}.
However, as the response data in the machine learning models and the disaggregation regression models are on different scales (prevalence is a proportion while incidence is a rate) we cannot simply take a weighted average of the predictions from the machine learning models as in a standard stacking scheme \citep{sill2009feature, hao2019review}.
Instead the predictions need to be transformed to the incidence scale with a seperately fitted model \citep{cameron2015defining}.
Applications in other disease contexts have used a similar stacking scheme where data from vector or wild-animal host species are used to train models, the predictions from which are then used as covariates in a final model \citep{pigott2014mapping, shearer2016estimating}.
In such applications we would always expect to need additional covariates as well as the modelled distributions of hosts or vectors.
However, in the case examined here, both sets of data are direct measures of some aspect of malaria transmission rate, and therefore it is possible, though not guaranteed, that we would not need any further covariates. 


Model stacking \citep{wolpert1992stacked} has proven effective in many realms \citep{bhatt2017improved, sill2009feature, hao2019review, breiman1996stacked}. 
Stacking improves predictions by controlling bias and variance; as long as suitably diverse models are averaged, they will have different biases while high variance in models should be averaged out.
This understanding of how stacking improves model performance indicates that diversity in models is important for stacking to be effective.
Diversity in models is typically created in two ways: by using diverse training datasets \citep{breiman1996bagging} (as in Random Forests for example) and by using functionally different models (for example by averaging tree based models and neural networks) \citep{breiman1996stacked}.
One important trade-off in spatial modelling is whether to use local data (with a smaller sample size but that is likely to be representative of the area of study) or global data that have a larger sample size but a less close association with the areas of study.
For the application of malaria mapping, we can think about diversity of training data in this context and expect that stacking seperate models trained on local and global data will also increase the diversity of predictions in a useful way.


To test the effectiveness of the proposed approach we used data from four countries: Madagascar, Colombia, Indonesia and Senegal.
We focused our analysis on comparing the predictive performance of disaggregation regression when given different sets of covariates.
Therefore we keep the structure of the disaggregation regression model the same and only vary the covariates provided to the model.
In each country we fitted stage 1 machine learning models trained on prevalence data and raw environmental covariates.
We made new covariates using predictions from these models.
We then tested whether stage 2 disaggregation regression models with these new covariates performed better than a baseline disaggregation regression model that directly used the raw environmental covariates.
We tested this approach using machine learning models trained on local prevalence data as well as models trained on a global prevalence dataset.
While there was no consistently best model we found that, in most cases, the two stage method worked better than the single stage baseline disaggregation regression models.
Using predictions from machine learning models, trained on local prevalence data as covariates improved the performance of disaggregation regression models relative to the disaggregation regression models that only used the raw environmental covariates.
In contrast, using predictions from machine learning models trained on the global prevalence dataset rarely improved predictive performance.

\section{Methods}

\subsection{Epidemiological Data}

We used two data sources that reflect \emph{P. falciparum} malaria transmission; point-prevalence surveys and polygon-level, aggregated incidence data. 
We selected Madagascar, Colombia, Indonesia and Senegal as case examples as they all have fairly complete, publicly available, surveillance data at a finer geographical resolution than administrative level one (i.e. higher resolution than state or province).
The prevalence survey data were extracted from the Malaria Atlas Project prevalence survey database using only data from 1990 onwards \citep{bhatt2015effect, guerra2007assembling, pfeffer2018ma}.
While the data covered a large time period, we did not model time explicitly as we are here focussed on spatial, rather than temporal modelling.
While we do expect there to be variation in time, as long as the spatial biases in sampling do not change through time, the temporal effects will not bias learned relationships as the model will still be learning relationships based on the relative changes along environmental variables.
The prevalence points were then standardised to an age range of 2--10 using the model from \citep{smith2007standardizing}.
This data was used as both a global dataset and as regional subsets.
The global dataset contains 55,914 surveys in 44,842 distinct locations and represents samples from 5,687,304 individuals.
As there were relatively few surveys in Colombia we used all points from South America (7,719 individuals from 522 locations) while for the other countries we used only data from that country (Madagascar: 89,381 individuals from 1,505 locations. Indonesia: 1,512,888 individuals from 4,778 locations. Senegal: 80,896 individuals from 1,762 locations).


The polygon incidence data (i.e. malaria incidence aggregated to administrative units) were collected from government reports \citep{mdg, sen, col, idn} and standardised using methods defined in \cite{cibulskis2011worldwide}.
This standardisation step accounts for missed cases due to lack of treatment seeking, missing case reports, and cases that sought medical attention outside the public health systems \citep{battle2016treatment}.
For reports where cases were not reported at the species level, national estimates of the ratio between \emph{P. falciparum} and \emph{Plasmodium vivax} cases were used to calculate \emph{P. falciparum} only cases. 
For incidence rates we divide by 1000 to give the Annual Parasite Index (API).
To keep the analysis focused on spatial estimates we selected one year of surveillance data for each country. 
We used annual surveillance data from 2013 for Madagascar (110 districts), 2015 for Colombia (952 municipalities), 2013 for Indonesia (244 regencies and cities) and 2009 for Senegal (34 departments).
These years were selected as they had the most complete data in each case.

Raster surfaces (i.e. population gridded to 5$ \times$ 5 km pixles) of population for the years 2005, 2010 and 2015, were created using data from WorldPop \citep{linard2012population,gaughan2013high,  sorichetta2015high} and from GPWv4 \citep{gpw4} where WorldPop did not have values. 
Population rasters for the remaining years were created by linear interpolation. 

\subsection{Raw Environmental Covariates}

We considered an initial suite of environmental and anthropological covariates, at a resolution of approximately $5 \times 5$ kilometres that included the annual mean and log standard deviation of land surface temperature, enhanced vegetation index, malaria parasite temperature suitability index, elevation, tasseled cap brightness, tasseled cap wetness, log accessibility to cities, log night lights and proportion of urban land cover \citep{weiss2014air, weiss2015re, weiss2018global}. 
Tasseled cap brightness and urban land cover were subsequently removed as they were highly correlated with other variables. 
The covariates were standardised and centered to have a mean of zero and a standard deviation of one. 
We refer to this set of transformed variables as the raw environmental covariates (even though some of the covariates are anthropogenic rather than environmental) to distinguish them from other covariates created from predictions from stage 1 machine learning models.
The raw environmental variables were used as covariates in the stage 1 machine learning models as well as being used directly as covariates in the baseline stage 2 dissaggregation regression models.



\subsection{Stage 1 machine learning models}


\begin{figure}[t!]
  \centering
  \includegraphics[width=0.8\textwidth]{figs/schematic2.pdf}
\caption{
  Schematic of the baseline disaggregation regression model (Enviro) and the two stage method (ML\textsubscript{l}). 
  Models are shown in yellow ovals, malaria data is shown in purple rectangles and covariates are shown in green rectangles.
  The baseline model (Enviro) uses aggregated incidence data and raw environmental covarates in a disaggregation regression model.
  In the two stage method (ML\textsubscript{l}), new covariates are created in stage 1 by training machine learning models on prevalence data.
  Predictions from these machine learning models are used as covariates in the stage 2 disaggregation regression.
  Only one of the two stage models (ML\textsubscript{l}) is shown for simplicity.
}
\label{f:schem}
\end{figure}


For each country specific dataset and for the global dataset we fitted 5 stage 1 models via \emph{caret} \citep{caret}: elastic net \citep{enet}, Random Forest \citep{wright2015ranger}, projection pursuit regression \citep{friedman1981projection}, neural networks \citep{nnet} and boosted regression trees (gradient boosted models, subsequently GBM) \citep{gbm}.
These models were fitted to both the full malaria prevalence dataset and to the regional subsets of the data.
Our response variable was prevalence and we weighted the data by sample size (i.e.\thinspace the number of people tested for malaria in each survey).
We used the raw environmental covariates described above as covariates in these machine learning models.
This process can therefore be seen as creating non-linear transformations of the raw covariates that are hopefully better correlated with malaria incidence than the raw environmental covariates are.
For each model we ran five-fold cross-validation to select hyperparameters using random search for Random Forest and boosted regression trees and grid search for the other models. 
Root mean square error (RMSE) was used to select the best performing model.
Predictions from these models were then made across each country respectively.
These predictions were empirical logit transformed so that they were on the linear predictor scale of the disaggregation regression model.
An empirical logit was used rather than a standard logit as there were many predictions of exactly zero.
These predicted surfaces were subsequently used as covariates in the stage 2 dissaggregation regression models (Figure~\ref{f:schem}).
The experiments that follow in this paper assess the performance of disaggregation regression models when using the predictions from these machine learning models as covariates as compared to a baseline disaggregation regression model using only the raw environmental covariates.
See the supplementary material for plots of the grid search hyperparameter performance, out-of-sample scatter plots and plots of the predicted surfaces.





\subsection{Stage 2 disaggregation regression}
The model fitted to aggregated incidence data was a disaggregation regression model \citep{sturrock2014fine, wilson2017pointless, law2018variational, taylor2017continuous, li2012log}.
The models were implemented and fitted using Template Model Builder \citep{TMB} in R \citep{R} and we note that these models cannot be fitted using INLA \citep{INLA} as we are not using a linear link function.
This model is defined by a likelihood at the level of the polygon with covariates and a spatial random field at the pixel-level. 
Values at the polygon-level are given the subscript $a$ while pixel level values are indexed with $b$.

The polygon case count data, $y_a$ is given a Poisson likelihood
$$y_a \sim \operatorname{Pois}(i_a\mathrm{pop_a})$$
where $i_a$ is the estimated polygon incidence rate and $\mathrm{pop_a}$ is the observed polygon population-at-risk. 
This polygon-level likelihood is linked to the pixel-level incidence and prevalence by
$$i_a = \frac{ \sum(i_b \mathrm{pop}_b)}{\sum  \mathrm{pop}_b} $$
$$i_b = 2.616p_b - 3.596p_b^2 + 1.594p_b^3$$
where the polynomial is  a function from a previously published model \citep{cameron2015defining}.
The fact that the model passes through prevalence space ensures that the predictions from the machine learning models can be appropriately scaled.
The linear predictor of the model is related to prevalence by a typical logit link function and includes: an intercept, $\beta_0$; covariates, $X$, with a vector of regression parameters, $\beta$; a spatial, Gaussian, random field, $u_b(\rho, \sigma_u)$; and an \emph{iid} random effect, $v_a(\sigma_v)$.
$$p_b = \operatorname{logit}^{-1}\left(\beta_0 + \beta X  + u_b\left(\rho, \sigma_u\right) + v_a\left(\sigma_v\right)\right)$$
The Gaussian spatial effect has a Mat\'ern covariance function and two hyperparameters: $\rho$, the nominal range (beyond which correlation is $< 0.1$) and $\sigma_u$, the marginal standard deviation.
The \emph{iid} random effect models both unobserved explanatory factors and extra-Poisson sampling error.
As described in more detail below we do not vary the structure of this model in the methodological comparison.
The matrix of covariates, $X$, it the only component that varies and is made up of various combinations of raw environmental covariates and predictions from the machine learning models.

Finally, we complete the model by setting priors on the parameters $\beta_0, \beta, \rho$ and $\sigma_u$ and $\sigma_v$. 
We assigned $\rho$ and $\sigma_u$ a joint penalised complexity prior \citep{fuglstad2018constructing} such that $P(\rho < 1) = 0.0001$ (except for Indonesia where we set $P(\rho < 3) = 0.0001$ due to its much larger size) and $P(\sigma_u > 1) = 0.0001$. 
This prior encoded our \emph{a priori} preference for a simpler, smoother random field.
We set this prior such that the random field could explain most of the range of the data if required.

We assigned $\sigma_v$ a penalised complexity prior \citep{simpson2017penalising} such that $P(\sigma_v > 0.05) =  0.0001$. 
This was based on a comparison of the variance of Poisson random variables, with rates given by the number of polygon-level cases observed, and an independently derived upper and lower bound for the case counts using the approach defined in \citep{cibulskis2011worldwide}. 
We found that an \emph{iid} effect with a standard deviation of 0.05 would be able to account for the discrepancy between the assumed Poisson error and the independently derived error.

Finally, we set different priors on the regression coefficients depending on which covariates were used.
When raw environmental covariates or a mix of raw environmental covariates and predictions from machine learning models were used we set the prior to be weakly regularising, $\beta_i \sim \operatorname{Norm}(0, 0.4)$, such that it was unlikely that any single covariate could explain the full range of the response data.
When only machine learning model predictions were used we set $\beta_i \sim \operatorname{ Norm}(\frac{1}{M}, 0.4)$ where $M$ is the number of machine learning models being used. 
This prior  sets our \emph{a priori} expectation that all the machine learning prediction models are positively and equally correlated with incidence i.e. this prior encodes standard model averaging.
It is important to note that this setup does not constitute true stacking in which we would enforce $\sum_i \beta_i = 1$ \citep{bhatt2017improved}.
In a preliminary analysis we tested the case where we force $\beta_i > 0$ which in practice is largely the same as the $\sum_i \beta_i = 1$  \citep{breiman1996stacked} but allows a small amount of flexibility to handle mispecification in $\mathrm{p2i}$.
This analysis did not show any benefits to this approach so it was not considered further.



\subsection{Experiments}



All experiments involve comparing predictive performance of stage 2 disaggregation regression models when different combinations of covariates are used.
We used the raw environmental covariates, centered and standardised, as a baseline stage 2 model (Figure~\ref{f:schem}).
We subsequently refer to this model as Enviro.
We then performed two experiments.
In the first (\emph{i}) we tested whether using predictions from stage 1 machine learning models trained on local (i.e. within-country) prevalence data improved predictions (Figure~\ref{f:schem}).
In the second (\emph{ii}) we tested whether using predictions from stage 1 machine learning models trained on global prevalence data improved predictions.
Our primary performance metric was correlation between observed and predicted aggregated  data.
We also examined the calibration of models by calculating the proportion of held out data that were within their 80\% credible intervals.


\begin{table}[t!]

\centering
\begin{tabular}{l >{\centering\arraybackslash}p{2cm}>{\centering\arraybackslash}p{1.55cm}>{\centering\arraybackslash}p{1.7cm}}
Model &  Environmental covariates & Local ML covariates &  Global ML covariates \\
\hline 
 \textbf{Experiment \emph{i}} & & &  \\
 Enviro &  \checkmark & & \\
 Enviro + ML\textsubscript{l} & \checkmark & \checkmark &\\\vspace{0.4cm}
 ML\textsubscript{l} &  & \checkmark & \\
 \textbf{Experiment \emph{ii}} & & &  \\
 Enviro &  \checkmark & & \\
 ML\textsubscript{g} &  &  & \checkmark\\
 ML\textsubscript{l} + ML\textsubscript{g} &  & \checkmark &  \checkmark
\end{tabular}
\caption{Summary of stage 2 models and the experiments they are grouped into. All models are disaggregation regression models fitted to aggregated incidence data. The only difference between the models is which covariates are being used. Environmental covariates includes the full set of eight variables. Local ML covariates are the predictions from stage 1 machine learning models, trained with local prevalence data and the eight environmental covariates as inputs. The local prevalence datasets are data from within each country except for Colombia where local prevalence refers to South American data. Global ML covariates are the predictions from stage 1 machine learning models, trained with global prevalence data (i.e. the full prevalence database) and the eight environmental covariates as inputs. Experiment \emph{i} tests whether including Local ML covariates improves predictive performance while Experiment \emph{ii} tests whether including Global ML covariates improves performance.}
\label{t:models}
\end{table}



In experiment \emph{i} we compared the baseline to two models that used locally trained machine learning models (Table~\ref{t:models}).
Firstly, we combined the predictions from the machine learning models and the environmental coviarates in one model (subsequently called Enviro + ML\textsubscript{l}).
In this model therefore, the environmental covariates are effectively used twice, once in their raw form and once in transformed form (i.e. the predictions from the machine learning models).
Secondly, we used only the predictions from the machine learning models (Figure~\ref{f:schem}) trained on local data (subsequantly called ML\textsubscript{l}).
As the environmental covariates are used as covariates in the machine learning models, this model is still ultimately driven by the values of the raw environmental covariates.
However, in this model we are only using the environmental covariates in the transformed space learned by the machine learning models.



In experiment \emph{ii} we compared the baseline model to two models that use predictions from machine learning models trained on the global dataset of prevalence surveys (Table~\ref{t:models}).
In the first, we used only predictions from the machine learning models trained on the global data (ML\textsubscript{g}).
In the second, we combined predictions from the machine learning models trained on regional data and predictions from the machine learning models trained on global data (ML\textsubscript{l} + ML\textsubscript{g}).


In each experiment we used two cross-validation schemes. 
In the first, polygon incidence data was randomly split into six cross-validation folds.
In the second, polygon incidence data was split spatially into k folds (via k-means clustering on the polygon centroids).
We set k as 3 for Madagascar and Colombia.
Due to its large size we set k as 7 for Indonesia.
Due to the small sample size, we set k as 5 for Senegal.
This spatial cross-validation scheme is testing the ability of the different models to make predictions far from data where the spatial random field is not informative.



\section{Results}



Table \ref{t:results} gives the correlation between observed and held out data (under random and spatial cross-validation) for experiment \emph{i} (models Enviro, ML\textsubscript{l} and Envir + ML\textsubscript{l}).
Many of the differences in performance are rather marginal.
Enviro was the best performing model in two cases (random cross-validation in Madagascar and Senegal).
In one case, Enviro perfomed equally well as another model; under spatial cross-validation in Senegal Enviro and Enviro + ML\textsubscript{l} performed equally well.
Of the remaining five cases, in two cases ML\textsubscript{l} performed best and in three cases Envir + ML\textsubscript{l} performed best.
The greatest benefits to using prediction from machine learning models instead of, or in combination with, the raw environmental variables occured under spatial cross-validation and in the cases when the Enviro model was particularly poor.

\begin{table}[t!]

\centering
\begin{tabular}{llrrrr}
Country &  Cross-validation & Enviro &  Enviro + ML\textsubscript{l} &  ML\textsubscript{l} \\
\hline 
 Colombia & Random &  0.59 & \textbf{0.61}& 0.59  \\
 Colombia &  Spatial &  0.12 &  0.25&  \textbf{0.33} \\
 Indonesia &  Random &  0.52 &  \textbf{0.59}&  0.48  \\
 Indonesia &  Spatial &  0.45 &  \textbf{0.51}&  0.44  \\
 Madagascar & Random &   \textbf{0.70}& 0.69 &  0.68  \\
 Madagascar &  Spatial &  0.22 & 0.18&  \textbf{0.55} \\
 Senegal &  Random &  \textbf{0.58} & 0.57&  0.51  \\
 Senegal &  Spatial &  0.63 &  0.63&  0.51  \\
\end{tabular}
\caption{Pearson correlations between observed and predicted values for experiment \emph{i}. }
\label{t:results}

\end{table}


\begin{figure}
  \includegraphics[width=\textwidth]{figs/cv1_l_scatter.png}
\caption{
  Observed data against predictions for random cross-validation hold-out samples on a square root transformed scale. 
  There are 12 cases composed of 4 countries (COL:, Colombia, IDN: Indonesia, MDG: Madagascar, SEN: Senegal) and three sets of covariates (Envir: raw environmental covariates only, Envir +  ML\textsubscript{l}: raw environmental covariates and machine learning covariates trained on local prevalence data combined, ML\textsubscript{l}: Machine learning models trained on local prevalence data only.
}
\label{f:scatter1}
\end{figure}


\begin{figure}
  \includegraphics[width=\textwidth]{figs/cv2_l_scatter.png}
\caption{
  Observed data against predictions for spatial cross-validation hold-out samples on a square root transformed scale.
  There are 12 cases composed of 4 countries (COL:, Colombia, IDN: Indonesia, MDG: Madagascar, SEN: Senegal) and three sets of covariates (Envir: raw environmental covariates only, Envir +  ML\textsubscript{l}: raw environmental covariates and machine learning covariates trained on local prevalence data combined, ML\textsubscript{l}: Machine learning models trained on local prevalence data only.
}
\label{f:scatter2}
\end{figure}

Figure~\ref{f:scatter1} shows scatter plots of the model performance under random cross-validation for experiment \emph{i} while Figure~\ref{f:scatter2} shows scatter plots of the model performance under spatial cross-validation.
It can be seen that without environmental covariates, the models in Madagascar fail to predict very high or very low values correctly.
Figure~\ref{f:map} shows the input data and spatial out-of-sample predictions of the Enviro model and ML\textsubscript{l} model in Colombia.



Table \ref{t:results2} gives the correlation between observed and held out data (under random and spatial cross-validation) for experiment \emph{ii} (models Enviro, ML\textsubscript{g} and ML\textsubscript{l} + ML\textsubscript{g}).
In six cases, Enviro was the best or tied best performing model.
The ML\textsubscript{g} model was never the best performing model and only outperforms Enviro in one case (spatial cross-validation in Madagascar).
In two cases ML\textsubscript{l} + ML\textsubscript{g} was the best performing model (spatial Colombia and spatial Madagascar).
Comparing across Tables \ref{t:results} and \ref{t:results2} we can see that ML\textsubscript{g} outperforms ML\textsubscript{l} once (spatial cross-validation in Senegal).
In only two cases (Spatial Senegal and Spatial Indonesia) did ML\textsubscript{l} + ML\textsubscript{g} outperform ML\textsubscript{l}.



\begin{figure}[t!]
\centering
\includegraphics[width = 1\textwidth]{figs/col_comparison_map.png} %\caption{Indonesia spatial crossvalidation} 
\caption{
  A) Observed data for Colombia (grey for zero incidence). B) Out-of-sample predictions for the spatial cross-validation, environmental covariates only model. C) Out-of-sample predictions for the spatial cross-validation, local machine learning only model. For each cross-validation fold, predictions are made for the held out data which are then combined to make a single surface.
}
\label{f:map}
\end{figure}

Table~\ref{t:coverage} shows the out-of-sample coverage of the 80\% credible intervals for all models, countries and cross-validation schemes.
The coverage in Colombia was very poor with no models achieving a coverage above 0.4.
The coverage was acceptable in the other three countries with most values lying between 0.7 and 0.9.
Overall there was a general tendancy for models to be slightly over confident.

We can examine the relationship between the RMSE of the machine learning models to their fitted regression coefficients (weights).
These values are given in Table~\ref{t:mlresults}.
In all five sets of machine learning models (four sets trained on local data and one set trained on global data), Random Forest performs the best.
We have not forced $\beta_i > 0$ but we have set the priors for these coefficients with a positive mean.
In nearly all cases the fitted values are positive.
If the prevalence data and incidence data are not biased relative to each other we would expect the models with the lowest RMSE to also have the biggest regression coefficient.
This occurs in three cases where Random Forest has the lowest RMSE and the biggest coefficient.
In a further two cases, Random Forest has the lowest RMSE but GBM has the highest coefficient.
The predictions from Random Forest and GBM are highly correlated in part because they both perform well and in part because they are both tree based models.
Finally, it can be seen that the relationship between RMSE and regression coefficients was much weaker in Indonesia.
For the models trained on local data a neural network has the highest fitted coefficient while for the models trained on global data an elastic net has the highest fitted coefficient.





%\begin{table}[h!]
%\caption{Pearson correlations between observed and predicted values. }
%\centering
%\begin{tabular}{llrrrr}
%Cross-validation scheme & Country &  Covariates &  ML\textsubscript{l} &  ML\textsubscript{g} & ML\textsubscript{l} + ML\textsubscript{g} \\
%\hline 
% Random &  Colombia & \textbf{0.59} & \textbf{0.59} &  0.58 & 0.56 \\
% Random &  Madagascar &  0.70 &  \textbf{0.73} &   0.70 & 0.71 \\
% Random &  Senegal &  \textbf{0.58} &  0.51 &  0.30 & 0.08 \\
% Random &  Indonesia &  \textbf{0.52} &  0.48 &  0.46 & 0.32 \\
% Spatial &  Colombia &  0.12 &  0.33 &  0.18 & \textbf{0.34}\\
% Spatial &  Madagascar &  0.22 &  \textbf{0.66} &  0.63 & 0.60\\
% Spatial &  Senegal &  \textbf{0.63} &  0.27 &  0.36 & 0.35 \\
% Spatial &  Indonesia &  \textbf{0.45} &  0.44 &  0.41 & \textbf{0.45} \\
%\end{tabular}
%\label{t:results}
%\end{table}

% to do table of coverage.





\begin{table}[t!]

\centering
\begin{tabular}{llrrrr}
Country &  Cross-validation & Enviro &   ML\textsubscript{g} & ML\textsubscript{l} + ML\textsubscript{g} \\
\hline 
 Colombia & Random &  \textbf{0.59} &0.55 & 0.58 \\
 Colombia &  Spatial &  0.12 &  0.12 & \textbf{0.33}\\
 Indonesia &  Random &  \textbf{0.52} & 0.32 & 0.46 \\
 Indonesia &  Spatial &  0.45 & 0.41 & 0.45 \\
 Madagascar &  Random &  \textbf{0.70} &  0.67 & 0.68 \\
 Madagascar &  Spatial &  0.22 &  0.51 & \textbf{0.55}\\
 Senegal &  Random &  \textbf{0.58} &  0.50 & 0.49 \\
 Senegal &  Spatial &   \textbf{0.63} & 0.55 & 0.52 \\

\end{tabular}
\caption{Pearson correlations between observed and predicted values for experiment \emph{ii}. }
\label{t:results2}

\end{table}



\begin{table}[t!]

\centering
\begin{tabular}{llrrrrr}
Country &  CV & Enviro & ML\textsubscript{l} &  Enviro + ML\textsubscript{l} & ML\textsubscript{g} & ML\textsubscript{l} + ML\textsubscript{g} \\
\hline 
 Colombia & Random & \textbf{0.28} & \textbf{0.28} & \textbf{0.29} & \textbf{0.28} & \textbf{0.30} \\
 Colombia &  Spatial & \textbf{0.30} & \textbf{0.33}  & \textbf{0.33} & \textbf{0.33} & \textbf{0.34}  \\
 Indonesia & Random &0.80 & 0.81& 0.78& 0.79& 0.77  \\
 Indonesia & Spatial & 0.80 & 0.78& 0.78& 0.76& 0.75  \\
 Madagascar &  Random & 0.80 & 0.77& 0.75& 0.77& 0.76 \\
 Madagascar & Spatial & \textbf{0.65} & 0.74& 0.70& 0.75 & 0.76   \\
 Senegal & Random &0.79 & 0.79& 0.79& 0.79& 0.82 \\
 Senegal & Spatial & 0.85 & \textbf{0.91}& 0.85& \textbf{0.94} & 0.85  \\
\end{tabular}
\caption{Coverage of 80\% credible intervals. Values outside 0.7--0.9 are shown in bold.}
\label{t:coverage}
\end{table}




\begin{table}[t!]

\centering
\small
\begin{tabular}{ll|rr|rr}
     Country          & Model &      RMSE\textsubscript{l} & $\beta_l$ & RMSE\textsubscript{g} & $\beta_g$ \\ \hline
Colombia & RF & \textbf{0.068} & 0.625 &  \textbf{0.169} & 0.180\\
Colombia & GBM & 0.073 & \textbf{0.952} & 0.178& -0.218  \\
Colombia & enet & 0.070 & 0.219 &0.233 & 0.183 \\
Colombia & nnet & 0.070 & 0.129 &0.220 & 0.527 \\
Colombia & ppr & 0.070 & 0.667 & 0.205 &  \textbf{0.546}\vspace{0.3cm}\\
Indonesia & RF& \textbf{0.081} & 0.447 & \textbf{0.169} & 0.178\\
Indonesia & GBM & 0.085 & 0.357 & 0.178& 0.289 \\
Indonesia & enet & 0.091 & 0.303 &0.233 & \textbf{0.526} \\
Indonesia & nnet & 0.089 & \textbf{0.506} &0.220 & 0.316 \\
Indonesia & ppr & 0.089 & 0.364 & 0.205 &  0.089\vspace{0.3cm}\\
Madagascar & RF & \textbf{0.100} & 0.538 &  \textbf{0.169} & \textbf{0.529}\\
Madagascar & GBM & 0.105 & \textbf{0.570} & 0.178& 0.432 \\
Madagascar & enet & 0.116 & 0.301 &0.233 & 0.262 \\
Madagascar & nnet & 0.113 & 0.033 &0.220 & 0.364 \\
Madagascar & ppr & 0.109 & 0.469 & 0.205 &  0.403\vspace{0.3cm}\\ 
Senegal & RF & \textbf{0.092} & \textbf{0.339} & \textbf{0.169} & \textbf{0.425} \\
Senegal & GBM & 0.099 & 0.261& 0.178& 0.408 \\
Senegal & enet& 0.103 & 0.344  &0.233 & 0.205 \\
Senegal & nnet & 0.099 & 0.254 &0.220 & 0.190 \\
Senegal & ppr & 0.098 & 0.268& 0.205 &  0.126\\


\end{tabular}
\caption{Machine learning model results and fitted parameters (i.e.\thinspace model weights) of the machine learning predictions only models (i.e. ML\textsubscript{l} local only and ML\textsubscript{g} global only). 
  For each dataset (the country and whether the data was local or global) the best model (lowest RMSE) is shown in bold. 
  Similary, the largest coefficient within each disaggregation model is shown in bold.}
\label{t:mlresults}
\end{table}







%\begin{table}
%\caption{Fitted regression parameters of the environmental and machine learning covariates for thee models: just environmental variables, just local machine learning models and the combination of the two.}
%\centering
%\tiny
%\begin{tabular}{ll|rrr}
%Country    & Variable &  $\beta_{enviro}$   & $\beta_l$ & $\beta_{enviro+l}$\\ \hline
%Madagascar & LST mean & 0.17 &  &  -0.01\\
%Madagascar & EVI & 0.32 &  & -0.04 \\
%Madagascar & TSI & 0.42 &  &0.06  \\
%Madagascar & access & 0.34 &  &0.00  \\
%Madagascar & Elev & -0.14 &  & 0.00\\ 
%Madagascar & LST sd & -0.78 &  &-0.04  \\
%Madagascar & VIIRS & -0.1 &  &-0.52  \\
%Madagascar & TCW & -0.22 &  & -0.06\\ 
%Madagascar & RF &  & 0.29 &  0.01\\
%Madagascar & GBM &  & 0.52 & 0.25 \\
%Madagascar & enet &  & 0.31 &0.09  \\
%Madagascar & nnet &  & 0.43 &0.14  \\
%Madagascar & ppr &  & 0.49 & 0.22\vspace{0.2cm}\\ 
%Colombia & LST mean &-0.12  &  & -0.22\\
%Colombia & EVI &  -0.08&  & 0.17\\
%Colombia & TSI &  0.54&  & -0.06\\
%Colombia & access &  0.35&  &0.00 \\
%Colombia & Elev &  0.47&  & 0.00\\
%Colombia & LST sd & -0.11 &  & -0.10\\
%Colombia & VIIRS & 0.24 &  & 0.01\\
%Colombia & TCW &  0.21&  & 0.00\\
%Colombia & RF &  & 0.36 & -0.18\\
%Colombia & GBM &  & 0.54 & 0.26\\
%Colombia & enet &  & 0.32 & -0.34\\
%Colombia & nnet &  &0.33  & -0.09\\
%Colombia & ppr &  & 0.54 & 0.01\vspace{0.2cm}\\
%Senegal & LST mean &-0.04  &  &-0.02\\
%Senegal & EVI &  0.33&  & 0.30\\
%Senegal & TSI &  -0.58&  &  -0.59\\
%Senegal & access & -0.03 &  &  -0.05\\
%Senegal & Elev &  0.42&  &0.37\\ 
%Senegal & LST sd &  0.21&  & 0.10 \\
%Senegal & VIIRS &  0.13&  &  0.13\\
%Senegal & TCW & 0.08 &  &-0.01\\ 
%Senegal & RF &  & 0.34 &  0.20\\
%Senegal & GBM &  &  0.28& 0.05\\
%Senegal & enet &  &  0.27&  -0.05\\
%Senegal & nnet &  & 0.29 &-0.09 \\
%Senegal & ppr &  &  0.35& 0.25\vspace{0.2cm}\\
%Indonesia & LST mean & -0.32 &  &-0.34\\
%Indonesia & EVI &  0.49&  & 0.36\\
%Indonesia & TSI &  0.58&  &0.52\\
%Indonesia & access &0.33 &  & 0.06 \\
%Indonesia & Elev& -0.06&  &-0.13\\ 
%Indonesia & LST sd & -0.23 &  & -0.33\\
%Indonesia & VIIRS &  -0.12&  & 0.03\\
%Indonesia & TCW& 0.12 &  &0.10\\ 
%Indonesia & RF &  & 0.32 & 0.06\\
%Indonesia & GBM &  &  0.38&0.03\\
%Indonesia & enet &  &  0.49&  0.56\\
%Indonesia & nnet &  &  0.36&  0.18\\
%Indonesia & ppr &  &  0.45& 0.32\\
%
%
%
%\end{tabular}
%\label{t:mlresults2}
%\end{table}
%


\section{Discussion}

We have studied the predictive performance of disaggregation regression of malaria incidence when provided with different sets of covariates.
Overall, experiment \emph{i} suggests that the predictions from the disaggregation models were better when using covariates created using predictions from machine learning models (trained on local prevalence points) than when using raw environmental covariates.
This increased performance comes despite the prevalence data being on a different scale and being measurements of a different aspects of malaria transmission as well as the fact that the model we have used to translate between the two scales is imperfect.
However, there was no clear best model between ML\textsubscript{l} and Enviro + ML\textsubscript{l}.
Therefore, when using these methods, both of these models should be fitted and the model with the best predictive performace for a given dataset selected.
Furthermore, many of the performance improvements are rather marginal. 
However, in a few cases such as Colombia and Madagascar under spatial cross-validation the performance boost is large.
For example, using just environmental covariates in Madagascar under spatial cross-validation gives a correlation between observed and predicted data of 0.22.
Such a model would be unusable for any applied or policy work.
In contrast, using the predictions from the machine learning models trained on local data gives a correlation value of 0.55, which while still relatively poor is possibly a useful model.

As expected, the model performance was generally worse under spatial cross-validation than under random cross-validation.
This implies that the models are still relying heavily on the spatial Gaussian random field.
Furthermore, the difference between random and spatial cross-validation is usually bigger than the difference between different models.
This suggests that better data coverage is more important than which specific model is used and that the models are still relying quite strongly on the random field.


% this method is an improvement
% still reliant on spatial field

% allows broad suite of covariates

% sum to one stacking

% global ml models, local experts

Overall, the models fitted using predictions from machine learning models trained on the global database of prevalence point-surveys were less good than those using either environmental data alone or than those using predictions from machine learning models trained on local data.
This in itself is not particularly surprising.
However, it does indicate that continental scale models should consider using a mosaic of locally trained machine learning models for example.
What is more surprising is that using both the ML\textsubscript{l} and ML\textsubscript{g} covariates together did not improve performance.
Given that this approach of creating diverse predictions is a core element of stacking methodology we would expect this set of covariates to perform as well or better than just the ML\textsubscript{l} covariates.

While the approach presented here is related to stacking, it differs in that we have not constrained the regression parameters to be positive nor included a sum-to-one constraint i.e.\thinspace the result is not simply a weighted average of the level zero model predictions.
We did not include these constraints because the first stage and second stage models were trained on response data on different scales.
However, given our priors, nearly all the fitted regression coefficients in models with only machine learning predictions were positive.
Therefore, in practice these models are working in a way similar to standard stacking.
However, the coefficients certainly do not sum to one, and fitted intercepts are negative to account for this.


Due to the low statistical power of typical aggregated incidence datasets, previous analyses using disaggregation regression used a small number of covariates \citep{sturrock2014fine}.
However, as models such as Random Forest and elastic net can robustly handle high dimensional data, future work could include many more covariates in the machine learning models, potentially increasing predictive performance.
However, for the sake of consistency, we have used the same environmental covariates in the machine learning models as in the Enviro disaggregation regression models.



\section{Conclusions}

Overall we find that including predictions from machine learning models trained on prevalence point-surveys can improve the performance of disaggregation regression models for malaria incidence relative to using raw environmental covariates.
This extra modelling step can be seen as finding useful, non-linear transformations of the raw environmental covariates.
This view is important for understanding how the model will predict in areas with no incidence data; in this situation the data cannot inform the Gaussian random field and predictions are driven by this non-linear transformation of the raw environmental covariates.
Training the machine learning models on local data (i.e. prevalence data from the same country or region as the incidence data) shows much better performance than when training the machine learning models on the full, global, dataset of prevalence point-surveys.
More countries, particularly those with medium or low malaria burdens, are providing timely and accurate routine surveillance data of malaria cases.
Therefore it may be expected that disaggregation regression may become more popular.
We have here presented a method for improving the predictive performance of these models by using ancillary, prevalence point-survey data.



\section*{Acknowledgments}
The authors acknowledge the National Malaria Control Programme of Madagascar for sharing their routine case data for this analysis.

\section*{Citations}
\bibliography{Malaria} 
%\bibliographystyle{unsrt}
%\bibliographystyle{apalike}




\end{document}









